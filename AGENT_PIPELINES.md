# Agent Pipelines Documentation

Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ»Ğ½Ğ°Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ²ÑĞµÑ… Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ¾Ğ² Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ² Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¸ **Second Me**. ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ ÑÑ…ĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ² Ğ¿Ñ€Ğ¾Ğ¼Ñ‚Ğ¾Ğ² Ğ¸ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¼ĞµĞ¶Ğ´Ñƒ ÑÑ‚Ğ°Ğ¿Ğ°Ğ¼Ğ¸.

## Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ğµ

1. [L0 - Insight Generation Pipeline](#l0---insight-generation-pipeline)
   - [Image Processing Pipeline](#image-processing-pipeline)
   - [Audio Processing Pipeline](#audio-processing-pipeline)
   - [Document Processing Pipeline](#document-processing-pipeline)
2. [L1 - User Profiling Pipeline](#l1---user-profiling-pipeline)
   - [Shade Creation Pipeline](#shade-creation-pipeline)
   - [Biography Generation Pipeline](#biography-generation-pipeline)
   - [Status Bio Pipeline](#status-bio-pipeline)
3. [L2 - Chat Processing Pipeline](#l2---chat-processing-pipeline)
   - [Context Enhancement Pipeline](#context-enhancement-pipeline)
   - [Judge (Expert Interface) Pipeline](#judge-expert-interface-pipeline)
   - [Memory Q&A Pipeline](#memory-qa-pipeline)
4. [Data Generation Pipelines](#data-generation-pipelines)
   - [Context Data Pipeline](#context-data-pipeline)
   - [Preference Data Pipeline](#preference-data-pipeline)
   - [SelfQA Data Pipeline](#selfqa-data-pipeline)
5. [GraphRAG Indexing Pipeline](#graphrag-indexing-pipeline)
6. [Space Discussion Pipeline](#space-discussion-pipeline)

---

## L0 - Insight Generation Pipeline

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸Ğ¼Ğ¾Ğ´Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ° (Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ, Ğ°ÑƒĞ´Ğ¸Ğ¾, Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹) Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚Ğ¾Ğ².

### Image Processing Pipeline

#### Ğ¡Ñ…ĞµĞ¼Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    IMAGE PROCESSING PIPELINE                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT: Image file(s) + User hint + User biography
  â”‚
  â”œâ”€> STEP 1: Classification
  â”‚   â”œâ”€ Prompt: insight_image_parser
  â”‚   â”œâ”€ Input: Image(s)
  â”‚   â”œâ”€ Output: Classification { "image": {"Step 1": ..., "Step 2": ..., "Step 3": "Emotion|Knowledge"} }
  â”‚   â””â”€ Decision: Route to Emotion or Knowledge processing
  â”‚
  â”œâ”€> STEP 2A: Overview Generation (for both Emotion & Knowledge)
  â”‚   â”œâ”€ Prompt: insight_image_overview
  â”‚   â”œâ”€ Input:
  â”‚   â”‚   - Image(s)
  â”‚   â”‚   - User hint
  â”‚   â”‚   - User biography (about_me, global_bio, status_bio)
  â”‚   â”‚   - Language preference (__language_desc__)
  â”‚   â”œâ”€ Output: { "Title": "...", "Opening": "..." }
  â”‚   â””â”€ Purpose: Generate catchy title and friendly opening
  â”‚
  â””â”€> STEP 2B: Breakdown Generation
      â”œâ”€ Prompt: insight_image_breakdown
      â”œâ”€ Input:
      â”‚   - Image(s)
      â”‚   - User hint
      â”‚   - Classification result (from Step 1)
      â”œâ”€ Output: { "Insight": ["insight1", "insight2", ...] }
      â”œâ”€ Purpose: Generate 2-8 caring, warm, and humorous insights
      â””â”€ Features:
          - Each insight: 4+ sentences, <100 words
          - Includes background knowledge and encyclopedia
          - Emotional connection and shared experiences

OUTPUT:
  - Title (â‰¤15 words)
  - Opening (â‰¤50 words)
  - Insights (2-8 items, each â‰¤100 words)
```

#### ĞŸĞ¾Ñ‚Ğ¾Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…:

1. **Input â†’ Classification**
   - Image pixels â†’ LLM vision model
   - Output: JSON Ñ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸ĞµĞ¹

2. **Classification + Biography â†’ Overview**
   - Image + hint + biography â†’ Overview prompt
   - Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ `__about_me__`, `__global_bio__`, `__status_bio__` placeholders
   - Output: Title + Opening

3. **Image + Hint â†’ Breakdown**
   - ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾ Ñ Overview (Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑ‚ÑŒÑÑ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾)
   - Focus Ğ½Ğ° meaning Ğ¸ key aspects
   - Output: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº insights

4. **Aggregation**
   - Title + Opening + Insights â†’ Final insight object
   - Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ÑÑ Ğ² Ğ±Ğ°Ğ·Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ĞºĞ°Ğº L0 memory

#### ĞÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°:

- **ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ**: Overview Ğ¸ Breakdown Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾ÑĞ»Ğµ Classification
- **ĞŸĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ**: Overview Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ user biography Ğ´Ğ»Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
- **Hint integration**: Hint ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ ÑĞ²ÑĞ·ÑŒ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
- **Emotion vs Knowledge**: Classification Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ tone (emotional vs informational)

---

### Audio Processing Pipeline

#### Ğ¡Ñ…ĞµĞ¼Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AUDIO PROCESSING PIPELINE                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT: Audio file + User hint
  â”‚
  â”œâ”€> PRE-STEP: Speech-to-Text (Transcription)
  â”‚   â”œâ”€ Service: Whisper / ASR model
  â”‚   â”œâ”€ Input: Audio file
  â”‚   â”œâ”€ Output: Timestamped transcript
  â”‚   â””â”€ Format: "<timestamp in seconds> <text>"
  â”‚
  â”œâ”€> VARIANT 1: Full Processing (Title + Overview + Breakdown)
  â”‚   â”‚
  â”‚   â”œâ”€ Prompt: insight_audio_parser
  â”‚   â”œâ”€ Input:
  â”‚   â”‚   - Timestamped speech transcript
  â”‚   â”‚   - User hint
  â”‚   â”œâ”€ Output: {
  â”‚   â”‚     "Title": "...",
  â”‚   â”‚     "Overview": "...",
  â”‚   â”‚     "Breakdown": {
  â”‚   â”‚       "ğŸš€<subtitle1>": [
  â”‚   â”‚         ["<key point>", "<explanation>", "<timestamps>"],
  â”‚   â”‚         ...
  â”‚   â”‚       ],
  â”‚   â”‚       ...
  â”‚   â”‚     }
  â”‚   â”‚   }
  â”‚   â””â”€ Purpose: Complete audio analysis in one pass
  â”‚
  â””â”€> VARIANT 2: Separated Processing (more control)
      â”‚
      â”œâ”€ STEP 1: Overview Only
      â”‚   â”œâ”€ Prompt: insight_audio_overview
      â”‚   â”œâ”€ Input: Timestamped speech + hint
      â”‚   â”œâ”€ Output: { "Title": "...", "Overview": "..." }
      â”‚   â””â”€ Purpose: Quick summary without detailed breakdown
      â”‚
      â””â”€ STEP 2: Breakdown Only (optional, called separately)
          â”œâ”€ Prompt: insight_audio_breakdown
          â”œâ”€ Input: Timestamped speech + hint
          â”œâ”€ Output: { "Breakdown": {...} }
          â””â”€ Purpose: Detailed thematic analysis
              - Up to 4 thematic sections
              - Each section: up to 3 key points with explanations
              - Timestamps for each explanation

OUTPUT:
  - Title (â‰¤15 words)
  - Overview (â‰¤200 words)
  - Breakdown (optional):
      - Thematic sections with emoji
      - Key conclusions and points
      - Comprehensive explanations with timestamps
```

#### ĞŸĞ¾Ñ‚Ğ¾Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…:

1. **Audio â†’ Transcription**
   ```
   Audio bytes
     â†“
   [Whisper/ASR Service]
     â†“
   Timestamped transcript:
   "0-5 Welcome to today's meeting"
   "5-12 We will discuss the quarterly results"
   ```

2. **Transcript â†’ LLM Analysis**
   ```
   Timestamped transcript + hint
     â†“
   [insight_audio_parser/overview/breakdown]
     â†“
   Structured JSON output
   ```

3. **Breakdown Structure**
   ```
   Speech analysis
     â†“
   Logical division into themes
     â†“
   For each theme:
     - Key conclusions (decisions, plans, strategies)
     - Explanations with examples
     - Corresponding timestamps
   ```

#### ĞÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°:

- **Timestamps preservation**: Ğ’ÑĞµ timestamps ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑÑ‚ÑÑ Ğ´Ğ»Ñ navigation
- **Thematic organization**: Speech Ğ´ĞµĞ»Ğ¸Ñ‚ÑÑ Ğ½Ğ° Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑĞµĞºÑ†Ğ¸Ğ¸
- **Actionable insights**: Ğ¤Ğ¾ĞºÑƒÑ Ğ½Ğ° concrete ideas, decisions, plans
- **Complete coverage**: "User has no need to listen the whole content"
- **Two modes**: Full (parser) vs Separated (overview + breakdown)

---

### Document Processing Pipeline

#### Ğ¡Ñ…ĞµĞ¼Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DOCUMENT PROCESSING PIPELINE                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT: Web content / PDF / Article + User hint + User biography
  â”‚
  â”œâ”€> PRE-STEP: Content Extraction
  â”‚   â”œâ”€ Web scraping (HTML â†’ markdown)
  â”‚   â”œâ”€ PDF parsing
  â”‚   â”œâ”€ Document parsing
  â”‚   â””â”€ Output: Clean text content
  â”‚
  â”œâ”€> STEP 1: Overview Generation
  â”‚   â”œâ”€ Prompt: insight_doc_overview
  â”‚   â”œâ”€ Input:
  â”‚   â”‚   - Document content
  â”‚   â”‚   - User hint
  â”‚   â”‚   - User biography (about_me, global_bio, status_bio)
  â”‚   â”œâ”€ Output: { "Title": "...", "Overview": "..." }
  â”‚   â”œâ”€ Process:
  â”‚   â”‚   1. Develop specific, descriptive title
  â”‚   â”‚   2. Analyze content through lens of user biography
  â”‚   â”‚   3. Emphasize practical, actionable aspects
  â”‚   â”‚   4. Connect to user's goals and context
  â”‚   â””â”€ Purpose: Personalized content summary
  â”‚
  â””â”€> STEP 2: Breakdown Generation
      â”œâ”€ Prompt: insight_doc_breakdown
      â”œâ”€ Input:
      â”‚   - Document content
      â”‚   - User hint
      â”œâ”€ Output: {
      â”‚     "Breakdown": {
      â”‚       "[Emoji]Title1": [
      â”‚         ["<key conclusion>", "<explanation>"],
      â”‚         ...
      â”‚       ],
      â”‚       ...
      â”‚     }
      â”‚   }
      â”œâ”€ Process:
      â”‚   1. Organize into up to 8 thematic sections
      â”‚   2. For each section: up to 3 key conclusions
      â”‚   3. Conclusions = decisions, plans, strategies, theories, methods
      â”‚   4. Add emoji for visual categorization
      â””â”€ Purpose: Structured knowledge extraction

OUTPUT:
  - Title (â‰¤7 words)
  - Overview (â‰¤100 words) - personalized to user
  - Breakdown (up to 8 sections):
      - Each with emoji icon
      - Up to 3 key conclusions per section
      - Detailed explanations
```

#### ĞŸĞ¾Ñ‚Ğ¾Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…:

1. **Raw Content â†’ Clean Text**
   ```
   HTML / PDF / Doc
     â†“
   [Content Extraction]
     - Remove ads, navigation
     - Parse tables, images
     - Convert to markdown
     â†“
   Clean text content
   ```

2. **Text + Biography â†’ Personalized Overview**
   ```
   Content + User biography
     â†“
   [insight_doc_overview]
     - Analyze through user's lens
     - What matters most to them?
     - How aligns with goals?
     â†“
   Personalized Title + Overview
   ```

3. **Text â†’ Structured Breakdown**
   ```
   Content
     â†“
   [insight_doc_breakdown]
     - Identify thematic sections
     - Extract key conclusions
     - Organize hierarchically
     â†“
   Breakdown with emoji sections
   ```

#### ĞÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°:

- **Personalization**: Overview Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ñ€Ğ¸Ğ·Ğ¼Ñƒ user biography
- **Error handling**: ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ scraping errors Ğ¸ parsing issues
- **Structured output**: Breakdown Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½ Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ‡ĞµÑĞºĞ¸ Ñ emoji
- **Actionable focus**: Key conclusions = practical outcomes
- **User-centric**: Overview highlights what matters to the user

---

### Note Summarization Pipeline

#### Ğ¡Ñ…ĞµĞ¼Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  NOTE SUMMARIZATION PIPELINE                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT: User note content + Optional filename
  â”‚
  â””â”€> SINGLE STEP: Summarization
      â”œâ”€ Prompt: NOTE_SUMMARY_PROMPT
      â”œâ”€ Input:
      â”‚   - Content (note text)
      â”‚   - Language preference (language_desc)
      â”‚   - Optional filename (filename_desc)
      â”œâ”€ Output: {
      â”‚     "title": "...",
      â”‚     "summary": "...",
      â”‚     "keywords": ["...", "...", ...]
      â”‚   }
      â””â”€ Purpose: Create searchable metadata for notes

OUTPUT:
  - Title (â‰¤20 words) - main subject and topic
  - Summary (â‰¤10 sentences or 200 words) - structure, details, concepts
  - Keywords (array) - concepts, entities, terms for search
```

#### ĞŸĞ¾Ñ‚Ğ¾Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…:

```
User note
  â†“
[NOTE_SUMMARY_PROMPT]
  - Extract main topic
  - Identify key entities and concepts
  - Generate concise summary
  â†“
Metadata (title, summary, keywords)
  â†“
[Storage & Indexing]
  - Store in vector database
  - Enable semantic search
  - Link to user's knowledge graph
```

#### ĞÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°:

- **Single-pass**: ĞĞ´Ğ½Ğ° LLM-Ğ²Ñ‹Ğ·Ğ¾Ğ² Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
- **Searchable**: Keywords Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ°
- **Multilingual**: ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼Ğ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ°
- **Filename integration**: ĞœĞ¾Ğ¶ĞµÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ filename ĞºĞ°Ğº Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚

---

## L1 - User Profiling Pipeline

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ğµ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ğ¼ĞµÑ€Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ²Ğ¾ÑĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ğ¹, Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ¾Ğ² Ğ¸ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ĞµĞ¹.

### Shade Creation Pipeline

**Shade** - ÑÑ‚Ğ¾ Ğ³Ñ€Ğ°Ğ½ÑŒ Ğ»Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ¸Ğ»Ğ¸ Ğ¾Ğ±Ğ»Ğ°ÑÑ‚ÑŒ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ¾Ğ².

#### Ğ¡Ñ…ĞµĞ¼Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SHADE CREATION PIPELINE                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT: Cluster of user memories (notes, excerpts) related to one interest
  â”‚
  â”œâ”€> STEP 1: Initial Shade Analysis
  â”‚   â”œâ”€ Prompt: SHADE_INITIAL_PROMPT
  â”‚   â”œâ”€ Input:
  â”‚   â”‚   - Personal creations (life episodes, feelings, essays)
  â”‚   â”‚   - Online excerpts (saved content from web)
  â”‚   â”‚   - Memory IDs and timestamps
  â”‚   â”œâ”€ Process:
  â”‚   â”‚   1. Identify main interest/hobby theme
  â”‚   â”‚   2. Generate domain name
  â”‚   â”‚   3. Determine user's role/aspect (e.g., "Bookworm", "Music Junkie")
  â”‚   â”‚   4. Choose representative icon (emoji)
  â”‚   â”‚   5. Write domain description and content
  â”‚   â”‚   6. Create timeline of interest evolution
  â”‚   â”œâ”€ Output: {
  â”‚   â”‚     "domainName": "...",
  â”‚   â”‚     "aspect": "...",
  â”‚   â”‚     "icon": "ğŸµ",
  â”‚   â”‚     "domainDesc": "...",
  â”‚   â”‚     "domainContent": "...",
  â”‚   â”‚     "domainTimelines": [...]
  â”‚   â”‚   }
  â”‚   â””â”€ Purpose: Create structured interest domain analysis
  â”‚
  â”œâ”€> STEP 2: Perspective Shifting
  â”‚   â”œâ”€ Prompt: PERSON_PERSPECTIVE_SHIFT_V2_PROMPT
  â”‚   â”œâ”€ Input: Shade from Step 1 (third person)
  â”‚   â”œâ”€ Process:
  â”‚   â”‚   - Convert "User" â†’ "you"
  â”‚   â”‚   - Make informal and friendly
  â”‚   â”‚   - Preserve original meaning
  â”‚   â”œâ”€ Output: {
  â”‚   â”‚     "domainName": "..." (unchanged),
  â”‚   â”‚     "domainDesc": "You enjoy..." (second person),
  â”‚   â”‚     "domainContent": "You have..." (second person),
  â”‚   â”‚     "domainTimeline": [...] (descriptions in second person)
  â”‚   â”‚   }
  â”‚   â””â”€ Purpose: Make shade more relatable to user
  â”‚
  â”œâ”€> STEP 3: Shade Merging (periodic, across all shades)
  â”‚   â”œâ”€ Prompt: SHADE_MERGE_DEFAULT_SYSTEM_PROMPT
  â”‚   â”œâ”€ Input: All existing shades
  â”‚   â”œâ”€ Process:
  â”‚   â”‚   1. Analyze core characteristics of each shade
  â”‚   â”‚   2. Identify semantic similarities
  â”‚   â”‚   3. Find mergeable groups (â‰¥2 shades per group)
  â”‚   â”œâ”€ Output: [
  â”‚   â”‚     ["shade_id1", "shade_id2"],  // Group 1 to merge
  â”‚   â”‚     ["shade_id3", "shade_id4"]   // Group 2 to merge
  â”‚   â”‚   ] or []
  â”‚   â””â”€ Purpose: Identify shades that should be consolidated
  â”‚
  â”œâ”€> STEP 4: Execute Merge (for each group from Step 3)
  â”‚   â”œâ”€ Prompt: SHADE_MERGE_PROMPT
  â”‚   â”œâ”€ Input: Multiple (>2) shade analysis contents
  â”‚   â”œâ”€ Process:
  â”‚   â”‚   1. Identify commonalities
  â”‚   â”‚   2. Extract general common interest domain
  â”‚   â”‚   3. Merge timelines from all sources
  â”‚   â”‚   4. Generate new icon, aspect, description
  â”‚   â”œâ”€ Output: {
  â”‚   â”‚     "newInterestName": "...",
  â”‚   â”‚     "newInterestAspect": "...",
  â”‚   â”‚     "newInterestIcon": "...",
  â”‚   â”‚     "newInterestDesc": "...",
  â”‚   â”‚     "newInterestContent": "...",
  â”‚   â”‚     "newInterestTimelines": [...]
  â”‚   â”‚   }
  â”‚   â””â”€ Purpose: Create unified shade from similar interests
  â”‚
  â””â”€> STEP 5: Shade Improvement (when new memories added)
      â”œâ”€ Prompt: SHADE_IMPROVE_PROMPT
      â”œâ”€ Input:
      â”‚   - Existing shade analysis (Pre-Version)
      â”‚   - New memories
      â”‚   - Previous memories
      â”œâ”€ Process:
      â”‚   1. Check relevance of new memories to domain
      â”‚   2. If relevant: update Description (if needed)
      â”‚   3. Update Content with new information
      â”‚   4. Add new timeline entries
      â”œâ”€ Output: {
      â”‚     "improveDesc": "..." or None,
      â”‚     "improveContent": "..." or None,
      â”‚     "improveTimelines": [...] or []
      â”‚   }
      â””â”€ Purpose: Incrementally update shade with new data

STORAGE:
  - Each shade stored in database with ID
  - Links to source memory IDs
  - Timeline preserves evolution history
```

#### ĞŸĞ¾Ñ‚Ğ¾Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ lifecycle):

```
                    NEW MEMORIES
                         â”‚
                         â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Memory Clustering        â”‚
         â”‚  (by topic/interest)      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                  â”‚
        â†“                                  â†“
   NEW CLUSTER                     EXISTING SHADE
        â”‚                                  â”‚
        â†“                                  â†“
[SHADE_INITIAL_PROMPT]            [SHADE_IMPROVE_PROMPT]
        â”‚                                  â”‚
        â†“                                  â†“
[PERSPECTIVE_SHIFT]               Update Desc/Content/Timeline
        â”‚                                  â”‚
        â†“                                  â†“
    NEW SHADE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ UPDATED SHADE
                         â”‚
                         â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ ALL SHADES COLLECTIONâ”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“ (periodic check)
          [SHADE_MERGE_DEFAULT_SYSTEM_PROMPT]
                         â”‚
                         â†“
              Mergeable groups identified?
                    /        \
                 Yes          No
                  â†“            â†“
         [SHADE_MERGE_PROMPT]  (keep as is)
                  â†“
           Merged shades
                  â†“
         Update collection
```

---

### Biography Generation Pipeline

#### Ğ¡Ñ…ĞµĞ¼Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  BIOGRAPHY GENERATION PIPELINE                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT: All user shades (interest domains) + Language preference
  â”‚
  â”œâ”€> STEP 1: Global Biography Generation
  â”‚   â”œâ”€ Prompt: GLOBAL_BIO_SYSTEM_PROMPT
  â”‚   â”œâ”€ Input: For each shade:
  â”‚   â”‚   - [Name]: Interest Domain Name
  â”‚   â”‚   - [Aspect]: Interest Domain Aspect
  â”‚   â”‚   - [Icon]: Representative icon
  â”‚   â”‚   - [Description]: Brief description
  â”‚   â”‚   - [Content]: Detailed activities and engagements
  â”‚   â”‚   - [Timelines]: Evolution timeline with dates
  â”‚   â”œâ”€ Process:
  â”‚   â”‚   1. Analyze personality traits from interests
  â”‚   â”‚   2. Overview main interests distribution
  â”‚   â”‚   3. Speculate on occupation and identity
  â”‚   â”œâ”€ Output: Comprehensive user profile (â‰¤200 words)
  â”‚   â”‚   - Key personality traits summary
  â”‚   â”‚   - Main interests overview
  â”‚   â”‚   - Probable occupation and identity info
  â”‚   â””â”€ Purpose: Multi-dimensional user profiling
  â”‚
  â”œâ”€> STEP 2: Language Localization (if needed)
  â”‚   â”œâ”€ Prompt: PREFER_LANGUAGE_SYSTEM_PROMPT
  â”‚   â”œâ”€ Input:
  â”‚   â”‚   - User's preferred language
  â”‚   â”‚   - Biography from Step 1
  â”‚   â”œâ”€ Output: Biography in user's language
  â”‚   â”‚   (proper nouns remain in original language)
  â”‚   â””â”€ Purpose: Localize while preserving entities
  â”‚
  â””â”€> STEP 3: Perspective Conversion
      â”œâ”€ Prompt: COMMON_PERSPECTIVE_SHIFT_SYSTEM_PROMPT
      â”œâ”€ Input: Biography (third person)
      â”œâ”€ Process:
      â”‚   1. Convert "User" â†’ "you"
      â”‚   2. Modify descriptions in:
      â”‚   â”‚   - User's Identity Attributes
      â”‚   â”‚   - User's Interests and Preferences
      â”‚   â”‚   - Conclusion
      â”‚   3. Enhance informality
      â”‚   4. Maintain original meaning and structure
      â”œâ”€ Output: Second-person biography
      â””â”€ Purpose: More friendly and relatable profile

OUTPUT:
  - global_bio: Multi-dimensional user profile
    - Personality traits
    - Interest distribution
    - Occupation speculation
  - Perspective: Second person ("you")
  - Language: User's preferred language
```

---

### Status Bio Pipeline

#### Ğ¡Ñ…ĞµĞ¼Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STATUS BIO PIPELINE                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT: All user memories (reverse chronological order) + Time period
  â”‚
  â””â”€> SINGLE STEP: Status Report Generation
      â”œâ”€ Prompt: STATUS_BIO_SYSTEM_PROMPT
      â”œâ”€ Input:
      â”‚   - {recent_type} Memory (e.g., "Weekly")
      â”‚   - Earlier Memory
      â”‚   - Memory types: Memo, Audio, Reads, Chats, Plan
      â”œâ”€ Process:
      â”‚   1. Read and analyze all memories
      â”‚   2. Identify specific activities participated
      â”‚   3. Merge memories of similar topics
      â”‚   4. Extract entity names and proper nouns
      â”‚   5. Analyze physical and emotional state changes
      â”‚   6. Generate two sections + health status
      â”œâ”€ Priority: Memo > Audio > Reads/Chats > Plan
      â”œâ”€ Output:
      â”‚   ## User Activities Overview ##
      â”‚   **{recent_type}**: [paragraph]
      â”‚   **Earlier**: [paragraph]
      â”‚   ## Physical and mental health status ##
      â”‚   [â‰¤50 words]
      â””â”€ Purpose: Current user status tracking

OUTPUT:
  - status_bio: User activity status report
  - Used in: L0 overview generation for contextualization
```

---

## L2 - Chat Processing Pipeline

**ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:** ĞŸĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼ Ñ‡ĞµÑ€ĞµĞ· ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ½Ğ¾Ğµ Ğ¾Ğ±Ğ¾Ğ³Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ¸ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ.

### Context Enhancement Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 CONTEXT ENHANCEMENT PIPELINE                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT: User's vague/general request
  â”‚
  â”œâ”€> STEP 1: Retrieve Relevant Context
  â”‚   â”œâ”€ Query: Vector search in user's memories
  â”‚   â”œâ”€ Input: User request embedding
  â”‚   â”œâ”€ Output: Top-K relevant notes, todos, past conversations
  â”‚   â””â”€ Sources: L0 memories, L1 shades, global_bio, status_bio
  â”‚
  â”œâ”€> STEP 2 (CoT version): Enrich Request
  â”‚   â”œâ”€ Prompt: CONTEXT_COT_PROMPT
  â”‚   â”œâ”€ Input:
  â”‚   â”‚   - User's initial request
  â”‚   â”‚   - Retrieved context (personal info, preferences, history)
  â”‚   â”‚   - User biography (global_bio)
  â”‚   â”œâ”€ Process (Chain-of-Thought):
  â”‚   â”‚   <think>
  â”‚   â”‚   1. Analyze focus of initial requirements
  â”‚   â”‚   2. Find connections to user's background
  â”‚   â”‚   3. Plan how to use this info to refine
  â”‚   â”‚   </think>
  â”‚   â”‚   <answer>
  â”‚   â”‚   Refined requirement (first person, same form)
  â”‚   â”‚   </answer>
  â”‚   â””â”€ Output: Enhanced, specific, personalized request
  â”‚
  â””â”€> OR STEP 2 (Non-CoT): Direct Enhancement
      â”œâ”€ Prompt: CONTEXT_PROMPT
      â”œâ”€ Output: Enhanced request (no thinking process shown)
      â””â”€ Use case: When CoT overhead not needed

OUTPUT: Personalized, context-rich request
  - Maintains original form (request/imperative)
  - Uses first person ("I", "my")
  - Adds relevant personal details
  - More specific and natural
```

**Key Points:**
- ĞĞ• Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ÑƒÑ‚Ğ¾Ñ‡Ğ½ÑĞµÑ‚ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
- Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ñ„Ğ¾Ñ€Ğ¼Ñƒ Ğ²Ñ‹Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
- Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚

---

### Judge (Expert Interface) Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  JUDGE/EXPERT INTERFACE PIPELINE                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

USER REQUEST â†’ EXPERT SOLUTION
  â”‚                â”‚
  â”‚                â†“
  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚    â”‚  Expert's Response  â”‚
  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚                â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â†’ JUDGE EVALUATION
                        â”‚
                        â†“
              [JUDGE_COT_PROMPT]
                        â”‚
              <think>
              1. Review user background & preferences
              2. Assess if expert response meets needs
              3. Determine if feedback/supplement needed
              </think>
                        â”‚
              <answer>
              - If satisfied: Polite acknowledgment
              - If not: Feedback + additional user info
              </answer>
                        â”‚
                        â†“
              Response to Expert
              (on behalf of user)

FLOW:
1. User â†’ "Second Me" â†’ Enhanced request â†’ Expert
2. Expert â†’ Response â†’ "Second Me" â†’ Evaluation
3. "Second Me" â†’ Feedback to expert OR Acceptance
4. Loop until user needs satisfied
```

**Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:**
- "Second Me" = Ğ¿Ğ¾ÑÑ€ĞµĞ´Ğ½Ğ¸Ğº Ğ¼ĞµĞ¶Ğ´Ñƒ user Ğ¸ expert
- ĞŸÑ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğµ
- ĞœĞ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ°
- Ğ—Ğ°Ñ‰Ğ¸Ñ‰Ğ°ĞµÑ‚ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑÑ‹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ

---

### Memory Q&A Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     MEMORY Q&A PIPELINE                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT: User question about their own data/history
  â”‚
  â”œâ”€> STEP 1: Memory Retrieval
  â”‚   â”œâ”€ Vector search: Find relevant memories
  â”‚   â”œâ”€ Graph search: Find connected entities
  â”‚   â”œâ”€ Filter: By date, type, tags
  â”‚   â””â”€ Output: Relevant memories, notes, todos
  â”‚
  â””â”€> STEP 2: Answer Generation
      â”œâ”€ Prompt: MEMORY_COT_PROMPT
      â”œâ”€ Input:
      â”‚   - User question
      â”‚   - Retrieved memories
      â”‚   - User biography
      â”‚   - Past records
      â”œâ”€ Process:
      â”‚   <think>
      â”‚   1. Analyze connection between question and background
      â”‚   2. Reason based on historical data
      â”‚   3. Ensure accuracy and relevance
      â”‚   </think>
      â”‚   <answer>
      â”‚   Precise, systematic, high-density answer
      â”‚   </answer>
      â””â”€ Output: Personalized answer based on memory

Criteria:
- Accuracy: Must cite sources from memories
- Helpfulness: Provide additional knowledge
- Comprehensiveness: Cover all relevant aspects
- Empathy: Show understanding and care
```

---

## GraphRAG Indexing Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GRAPHRAG INDEXING PIPELINE                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT: User's text documents/notes
  â”‚
  â”œâ”€> STEP 1: Entity & Relationship Extraction
  â”‚   â”œâ”€ Prompt: extract_graph.txt
  â”‚   â”œâ”€ Input:
  â”‚   â”‚   - Text document
  â”‚   â”‚   - Entity types: [ORGANIZATION, PERSON, GEO, EVENT, ...]
  â”‚   â”œâ”€ Process:
  â”‚   â”‚   1. Identify all entities with descriptions
  â”‚   â”‚   2. Find all related entity pairs
  â”‚   â”‚   3. Describe relationships
  â”‚   â”‚   4. Assign relationship strength (score)
  â”‚   â”œâ”€ Output:
  â”‚   â”‚   ("entity"{tuple_delimiter}NAME{tuple_delimiter}TYPE{tuple_delimiter}DESC)
  â”‚   â”‚   ("relationship"{tuple_delimiter}SOURCE{tuple_delimiter}TARGET{tuple_delimiter}DESC{tuple_delimiter}STRENGTH)
  â”‚   â””â”€ Purpose: Extract knowledge graph from text
  â”‚
  â”œâ”€> STEP 2: Entity Description Consolidation
  â”‚   â”œâ”€ Prompt: summarize_descriptions.txt
  â”‚   â”œâ”€ Input:
  â”‚   â”‚   - Entity name(s)
  â”‚   â”‚   - List of descriptions from different sources
  â”‚   â”œâ”€ Process:
  â”‚   â”‚   1. Concatenate all descriptions
  â”‚   â”‚   2. Resolve contradictions
  â”‚   â”‚   3. Create coherent summary
  â”‚   â”œâ”€ Output: Single comprehensive entity description
  â”‚   â””â”€ Purpose: Merge duplicate entities
  â”‚
  â”œâ”€> STEP 3: Graph Construction
  â”‚   â”œâ”€ Create nodes for entities
  â”‚   â”œâ”€ Create edges for relationships
  â”‚   â”œâ”€ Add properties: type, description, strength
  â”‚   â””â”€ Store in graph database (Neo4j, etc.)
  â”‚
  â””â”€> STEP 4: Community Detection (optional)
      â”œâ”€ Leiden algorithm for clustering
      â”œâ”€ Identify communities of related entities
      â””â”€ Generate community summaries

RESULT: Knowledge Graph
  - Nodes: Entities with rich descriptions
  - Edges: Weighted relationships
  - Communities: Thematic clusters
  - Enables: Semantic search, Q&A, reasoning
```

**Data Flow:**
```
Documents â†’ [extract_graph] â†’ Entities + Relationships
                                    â”‚
                                    â†“
                        Group by entity name
                                    â”‚
                                    â†“
              [summarize_descriptions] â†’ Merged entities
                                    â”‚
                                    â†“
                            Graph Database
                                    â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â†“                   â†“                   â†“
          Vector Index      Community Index      Full Graph
                â†“                   â†“                   â†“
         Semantic Search    Thematic Q&A        Graph Reasoning
```

---

## Space Discussion Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SPACE DISCUSSION PIPELINE                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Multi-party AI discussion where "Second Me" represents the user

SETUP:
  - Topic: Discussion subject
  - Participants: User's "Second Me" + Other AI agents/experts
  - Rounds: Multiple turns of discussion

FLOW:
  â”‚
  â”œâ”€> ROUND START: Host Opening
  â”‚   â”œâ”€ Prompt: HostOpeningStrategy
  â”‚   â”œâ”€ Input:
  â”‚   â”‚   - Discussion topic
  â”‚   â”‚   - User's perspective/interests (from global_bio)
  â”‚   â”‚   - Context from previous rounds (if any)
  â”‚   â”œâ”€ Output: Opening statement representing user
  â”‚   â””â”€ Purpose: Introduce user's viewpoint
  â”‚
  â”œâ”€> DISCUSSION: Multi-turn exchange
  â”‚   â”œâ”€ Participants take turns
  â”‚   â”œâ”€ "Second Me" responds based on:
  â”‚   â”‚   - User's bio and preferences
  â”‚   â”‚   - Previous statements in discussion
  â”‚   â”‚   - User's shades and interests
  â”‚   â””â”€ Maintains user's voice and perspective
  â”‚
  â””â”€> ROUND END: Summary Generation
      â”œâ”€ Prompt: HostSummaryStrategy
      â”œâ”€ Input: All statements from current round
      â”œâ”€ Output: Summary of key points
      â”‚   - What was discussed
      â”‚   - Agreements and disagreements
      â”‚   - User's position
      â””â”€ Purpose: Consolidate round insights

COMPLETE FLOW:
  Topic â†’ Opening â†’ Discussion â†’ Summary
            â†“          â†“            â†“
        Round 1 â†’ Round 2 â†’ ... â†’ Round N
            â†“          â†“            â†“
         Summaries accumulate â†’ Final synthesis
```

**Purpose:**
- Represent user in multi-party discussions
- Maintain consistent user perspective
- Enable asynchronous collaboration
- Generate discussion summaries

---

## Summary: Complete Second Me System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  COMPLETE SECOND ME SYSTEM                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

USER INPUTS (Multimodal)
  â”‚
  â”œâ”€ Images â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”œâ”€ Audio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”œâ”€ Documents â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â†’ L0 INSIGHT GENERATION
  â””â”€ Notes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
                                       â†“
                               Processed Insights
                               (Title, Overview, Breakdown)
                                       â”‚
                                       â†“
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚   MEMORY STORAGE     â”‚
                            â”‚  (Vector Database)   â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â†“              â†“              â†“
                   L1 PROFILING   GraphRAG     L2 RETRIEVAL
                        â”‚         Indexing          â”‚
                        â†“              â†“            â†“
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ Shades  â”‚   â”‚  Graph  â”‚  â”‚Context  â”‚
                   â”‚Global   â”‚   â”‚  Nodes  â”‚  â”‚Enhanced â”‚
                   â”‚Bio      â”‚   â”‚  Edges  â”‚  â”‚Requests â”‚
                   â”‚Status   â”‚   â”‚Communitiesâ”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
                        â”‚              â”‚           â”‚
                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  USER PROFILE   â”‚
                      â”‚  (Complete)     â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â†“              â†“              â†“
         CHAT INTERFACE   SPACE DISCUSSIONS  DPO TRAINING
         (Context+Judge)  (Multi-party)      (Preference)
                â†“              â†“              â†“
         Personalized    User Represented   Model Improved
         Responses       in Discussions     Over Time
```

**Key Integration Points:**

1. **L0 â†’ L1**: Insights feed shade creation and status tracking
2. **L1 â†’ L2**: Biography enables context enhancement
3. **All â†’ GraphRAG**: Continuous knowledge graph building
4. **L0 + L1 â†’ Chat**: Rich context for personalized responses
5. **DPO**: Continuous improvement through preference learning

---

## Conclusion

Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° **Second Me** Ñ€ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞµÑ‚ ÑĞ»Ğ¾Ğ¶Ğ½ÑƒÑ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²ÑƒÑ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñƒ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…:

### Ğ£Ñ€Ğ¾Ğ²Ğ½Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸:
- **L0**: Multimodal insight extraction (ÑÑ‹Ñ€Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ â†’ Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚Ñ‹)
- **L1**: User profiling (Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚Ñ‹ â†’ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ)
- **L2**: Personalized interaction (Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ + Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ â†’ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚)

### ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ñ‹:
1. **Insight Generation**: Image/Audio/Doc â†’ Structured insights
2. **Shade Management**: Memories â†’ Interest domains â†’ Biography
3. **Context Enhancement**: Vague request â†’ Specific, personalized request
4. **Memory Q&A**: Question â†’ Memory retrieval â†’ Accurate answer
5. **GraphRAG**: Documents â†’ Knowledge graph â†’ Semantic reasoning
6. **Space Discussion**: Topic â†’ Multi-agent discussion â†’ Summary

### ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸:
- **Chain-of-Thought**: Explicit reasoning before answers
- **Multi-phase Processing**: Complex tasks split into steps
- **Incremental Updates**: Shades improve with new data
- **Perspective Shifting**: Third person â†’ Second person conversion
- **Merging & Consolidation**: Duplicate detection and combining

Ğ’ÑÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ²Ğ¼ĞµÑÑ‚Ğµ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ AI-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ°, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ **Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°ĞµÑ‚**, **Ğ·Ğ°Ğ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°ĞµÑ‚**, Ğ¸ **Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚** Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ.
